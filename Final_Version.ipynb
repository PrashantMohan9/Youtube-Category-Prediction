{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtbe Video Category Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix , classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv(\"Final.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.drop(['Unnamed: 0', 'link'], axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ep 1| Travelling through North East India | Of...</td>\n",
       "      <td>The journey to Arunachal, North East India beg...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Backpacking In Meghalaya | NorthEast India Tri...</td>\n",
       "      <td>In this video I explored North East India, sta...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Best Places to Visit in Austria - Travel Video</td>\n",
       "      <td>Austria is a country that is as well known for...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salzburg Vacation Travel Guide | Expedia</td>\n",
       "      <td>https://www.expedia.com/Salzburg.d180...\\n\\nTh...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vienna Vacation Travel Guide | Expedia</td>\n",
       "      <td>https://www.expedia.com/Vienna.d17831...\\n\\nOn...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Ep 1| Travelling through North East India | Of...   \n",
       "1  Backpacking In Meghalaya | NorthEast India Tri...   \n",
       "2  10 Best Places to Visit in Austria - Travel Video   \n",
       "3           Salzburg Vacation Travel Guide | Expedia   \n",
       "4             Vienna Vacation Travel Guide | Expedia   \n",
       "\n",
       "                                         description      category  \n",
       "0  The journey to Arunachal, North East India beg...  Travel Blogs  \n",
       "1  In this video I explored North East India, sta...  Travel Blogs  \n",
       "2  Austria is a country that is as well known for...  Travel Blogs  \n",
       "3  https://www.expedia.com/Salzburg.d180...\\n\\nTh...  Travel Blogs  \n",
       "4  https://www.expedia.com/Vienna.d17831...\\n\\nOn...  Travel Blogs  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.dropna(inplace=True)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words(\"english\")\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lmt = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['title'] = final['title'].apply(str)\n",
    "final['description'] = final['description'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "final = shuffle(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(final[['title', 'description']],final[['category']], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokkenizing\n",
    "title= []\n",
    "for i in range(len(final)):\n",
    "    required = (word_tokenize(final['title'].iloc[i]))\n",
    "    title.append(required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "description= []\n",
    "for i in range(len(final)):\n",
    "    required = (word_tokenize(final['description'].iloc[i]))\n",
    "    description.append(required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title)==len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(words):\n",
    "    after_clean_words = []\n",
    "    for word in words:\n",
    "        if word.lower() not in stopwords:\n",
    "            pos = pos_tag([word])\n",
    "            clean_word = lmt.lemmatize(word,pos=get_simple_pos(pos[0][1]))\n",
    "            after_clean_words.append(clean_word)\n",
    "    return after_clean_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.append(\"like\")\n",
    "stopwords.append(\"subscribe\")\n",
    "stopwords.append(\"comment\")\n",
    "stopwords.append(\"?\")\n",
    "stopwords.append(\"|\")\n",
    "stopwords.append(\":\")\n",
    "stopwords = stopwords + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_title = [(clean_data(t)) for t in title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_description = [(clean_data(d)) for d in description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['title']=final_title\n",
    "final['description']=final_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>[Purpose, concept, art, music]</td>\n",
       "      <td>[short, film, concept, Alex, Bourne, Wilkie]</td>\n",
       "      <td>Art &amp; Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>[HISTORY, IDEAS, Romanticism]</td>\n",
       "      <td>[Romanticism, historical, movement, still, hug...</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>[EPIC, EID, FEAST, Oman, Middle, Eastern, Trad...</td>\n",
       "      <td>[ðŸŽ¥UNSEEN, Desert, Food, Oman, â€™, Bedouin, Peop...</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>[Taipei, Taiwan, Food, Travel, Blog, 1, Din, T...</td>\n",
       "      <td>[www.imalwayseating.com, instagram, taesungsay...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>[10, Shortest, Matches, WWE, History]</td>\n",
       "      <td>[top, 10, quick, Wrestling, match, history, WW...</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "2677                     [Purpose, concept, art, music]   \n",
       "2260                      [HISTORY, IDEAS, Romanticism]   \n",
       "1293  [EPIC, EID, FEAST, Oman, Middle, Eastern, Trad...   \n",
       "251   [Taipei, Taiwan, Food, Travel, Blog, 1, Din, T...   \n",
       "1990              [10, Shortest, Matches, WWE, History]   \n",
       "\n",
       "                                            description      category  \n",
       "2677       [short, film, concept, Alex, Bourne, Wilkie]   Art & Music  \n",
       "2260  [Romanticism, historical, movement, still, hug...       History  \n",
       "1293  [ðŸŽ¥UNSEEN, Desert, Food, Oman, â€™, Bedouin, Peop...          Food  \n",
       "251   [www.imalwayseating.com, instagram, taesungsay...  Travel Blogs  \n",
       "1990  [top, 10, quick, Wrestling, match, history, WW...       History  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['title']=final['title'].apply(', '.join)\n",
    "final['description']=final['description'].apply(', '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X = CountVectorizer(max_features = 3000,tokenizer=lambda doc: doc, lowercase=False).fit_transform(final_title,final_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "category=final['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = final.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, final.iloc[:, 2], test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection, naive_bayes\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= Naive.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.92746113989638\n"
     ]
    }
   ],
   "source": [
    "print(Naive.score(x_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Art & Music       0.97      0.99      0.98       102\n",
      "         Food       0.97      0.97      0.97        92\n",
      "      History       0.97      0.98      0.97        92\n",
      "Manufacturing       1.00      1.00      1.00        58\n",
      "      Science       0.97      0.97      0.97        99\n",
      " Travel Blogs       1.00      0.98      0.99       136\n",
      "\n",
      "     accuracy                           0.98       579\n",
      "    macro avg       0.98      0.98      0.98       579\n",
      " weighted avg       0.98      0.98      0.98       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  97.23661485319516\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(x_train, y_train)\n",
    "\n",
    "pred_SVM = SVM.predict(x_test)\n",
    "\n",
    "print(\"Accuracy= \",accuracy_score(y_test,pred_SVM)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Art & Music       1.00      1.00      1.00       102\n",
      "         Food       0.99      0.97      0.98        92\n",
      "      History       0.98      1.00      0.99        92\n",
      "Manufacturing       1.00      0.93      0.96        58\n",
      "      Science       0.95      0.94      0.94        99\n",
      " Travel Blogs       0.94      0.98      0.96       136\n",
      "\n",
      "     accuracy                           0.97       579\n",
      "    macro avg       0.98      0.97      0.97       579\n",
      " weighted avg       0.97      0.97      0.97       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "xgb_model = xgb.XGBClassifier(max_depth=55, n_estimators=100, learning_rate=0.1, colsample_bytree=.7, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(x_train, y_train) \n",
    "xgb_prediction = xgb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.71848013816926\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, xgb_prediction)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Art & Music       0.99      0.99      0.99       102\n",
      "         Food       0.97      0.97      0.97        92\n",
      "      History       0.98      0.98      0.98        92\n",
      "Manufacturing       1.00      0.93      0.96        58\n",
      "      Science       0.92      0.98      0.95        99\n",
      " Travel Blogs       0.97      0.95      0.96       136\n",
      "\n",
      "     accuracy                           0.97       579\n",
      "    macro avg       0.97      0.97      0.97       579\n",
      " weighted avg       0.97      0.97      0.97       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, xgb_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
